knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tufte)
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python, for example:
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this path after your R and Python architectures match
# use_python("/absolute/path/to/your/venv/bin/python", required = TRUE)
# Python driver that runs EZ PPO training / evaluation
# src/ez_runner.py is created separately and imported here
source_python("src/ez_runner.py")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tufte)
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)
library(glmnet)
library(ggplot2)
library(reticulate)
# R helpers for data extraction and cleaning
source("R/data_preprocessing.R")
# Ensure the CSV for Python exists
if (!file.exists("data/processed/Total_data_for_python.csv")) {
message("Building Total_data_for_python.csv via build_total_data() ...")
Total_data <- build_total_data()
} else {
# Load for R-side analysis if you like
Total_data <- readRDS("data/Total_data.rds")
}
# IMPORTANT:
# Point reticulate at the exact Python you use for EZ_Optimization.
# Edit the path below to your venv python.
# Example for your setup (change if your path is different):
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Uncomment and fix this line once the path is correct
# use_python("/Users/james/Desktop/GitHub/EZ_Optimization/venv/bin/python", required = TRUE)
# Optional sanity check: see what Python reticulate is using
# py_config()
# Python bridge that imports from src.train etc
# ez_runner.py should sit in the project root, not inside src/
source_python("ez_runner.py")
Total_data <- build_total_data()
glimpse(Total_data)
summary(Total_data$predicting_return)
cat("Any NA? ", anyNA(Total_data), "\n")
cat("Number of rows: ", nrow(Total_data), "\n")
range(Total_data$predicting_date)
# pairwise correlations between future return and predictors
cors <- cor(
Total_data$predicting_return,
Total_data %>% dplyr::select(-predicting_date, -predicting_return)
)
cors
# 5 year rolling correlations
Rolling_corr <- Total_data %>%
dplyr::select(predicting_date, -predicting_return)
var_names <- names(Rolling_corr)[names(Rolling_corr) != "predicting_date"]
Rolling_corr[, var_names] <- NA_real_
window_len <- 60
for (i in 1:(nrow(Total_data) - window_len + 1)) {
idx <- i:(i + window_len - 1)
Rolling_corr$predicting_date[i + window_len - 1] <- Total_data$predicting_date[i + window_len - 1]
Rolling_corr[i + window_len - 1, var_names] <- cor(
Total_data$predicting_return[idx],
Total_data[idx, var_names]
)
}
Rolling_corr_long <- Rolling_corr %>%
tidyr::drop_na() %>%
tidyr::pivot_longer(-predicting_date,
names_to = "Variable",
values_to = "rolling_corr")
# define predictors explicitly (everything except date and target)
pred_vars <- setdiff(names(Total_data), c("predicting_date", "predicting_return"))
lambda_grid <- 10 ^ seq(-3, 3, length.out = 40)
cv_errors  <- numeric(length(lambda_grid))
Testing_result <- Total_data %>%
dplyr::filter(lubridate::year(predicting_date) >= 2009) %>%
dplyr::transmute(
predicting_date,
actual_return = predicting_return,
fitted_return_OLS   = NA_real_,
fitted_return_LASSO = NA_real_
)
for (i_year in 2009:2024) {
train_ols <- Total_data %>%
dplyr::filter(lubridate::year(predicting_date) < i_year)
# LASSO training and validation split
train_start <- 1985
val_start   <- i_year - 8
train_lasso <- Total_data %>%
dplyr::filter(lubridate::year(predicting_date) >= train_start,
lubridate::year(predicting_date) < val_start)
val_lasso <- Total_data %>%
dplyr::filter(lubridate::year(predicting_date) >= val_start,
lubridate::year(predicting_date) < i_year)
test_x <- Total_data %>%
dplyr::filter(lubridate::year(predicting_date) == i_year) %>%
dplyr::select(dplyr::all_of(pred_vars))
x_train <- train_lasso %>% dplyr::select(dplyr::all_of(pred_vars)) %>% as.matrix()
y_train <- train_lasso$predicting_return
x_val <- val_lasso %>% dplyr::select(dplyr::all_of(pred_vars)) %>% as.matrix()
y_val <- val_lasso$predicting_return
for (j in seq_along(lambda_grid)) {
m_lasso <- glmnet(x_train, y_train, alpha = 1, lambda = lambda_grid[j])
y_pred_val <- as.numeric(predict(m_lasso, newx = x_val))
cv_errors[j] <- mean((y_val - y_pred_val) ^ 2)
}
best_lambda <- lambda_grid[which.min(cv_errors)]
x_tv <- rbind(x_train, x_val)
y_tv <- c(y_train, y_val)
m_lasso_best <- glmnet(x_tv, y_tv, alpha = 1, lambda = best_lambda)
x_test_mat <- as.matrix(test_x)
y_pred_test_lasso <- as.numeric(predict(m_lasso_best, newx = x_test_mat))
# benchmark OLS on all data before i_year
m_ols <- lm(
predicting_return ~ . - predicting_date,
data = train_ols
)
y_pred_test_ols <- predict(
m_ols,
newdata = Total_data %>% dplyr::filter(lubridate::year(predicting_date) == i_year)
)
Testing_result$fitted_return_LASSO[lubridate::year(Testing_result$predicting_date) == i_year] <- y_pred_test_lasso
Testing_result$fitted_return_OLS[lubridate::year(Testing_result$predicting_date) == i_year]   <- y_pred_test_ols
}
head(Testing_result)
R_Sq_oos <- function(actual, fitted) {
1 - sum((actual - fitted) ^ 2) / sum(actual ^ 2)
}
r2_ols   <- R_Sq_oos(Testing_result$actual_return, Testing_result$fitted_return_OLS)
r2_lasso <- R_Sq_oos(Testing_result$actual_return, Testing_result$fitted_return_LASSO)
cat("OOS R^2 OLS   :", r2_ols, "\n")
cat("OOS R^2 LASSO :", r2_lasso, "\n")
ggplot(Testing_result) +
geom_point(aes(x = actual_return,
y = actual_return - fitted_return_OLS,
color = "OLS"),
alpha = 0.7) +
geom_point(aes(x = actual_return,
y = actual_return - fitted_return_LASSO,
color = "LASSO"),
alpha = 0.7) +
geom_smooth(aes(x = actual_return,
y = actual_return - fitted_return_OLS,
color = "OLS"),
method = "lm", se = TRUE) +
geom_smooth(aes(x = actual_return,
y = actual_return - fitted_return_LASSO,
color = "LASSO"),
method = "lm", se = TRUE) +
labs(
x = "Actual next month return",
y = "Residual",
color = "Model",
title = "Residual vs actual for expanding window OLS and LASSO"
) +
theme_minimal() +
theme(legend.position = "top")
Trading_Strategy <- Testing_result %>%
dplyr::mutate(
Trade_OLS   = (fitted_return_OLS   > 0),
Trade_LASSO = (fitted_return_LASSO > 0),
ret_OLS     = Trade_OLS   * actual_return,
ret_LASSO   = Trade_LASSO * actual_return
)
Trading_Strategy$CR_OLS      <- NA_real_
Trading_Strategy$CR_LASSO    <- NA_real_
Trading_Strategy$CR_BuyHold  <- NA_real_
Trading_Strategy$CR_OLS[1]      <- 1
Trading_Strategy$CR_LASSO[1]    <- 1
Trading_Strategy$CR_BuyHold[1]  <- 1
for (i in 2:nrow(Trading_Strategy)) {
Trading_Strategy$CR_OLS[i] <-
Trading_Strategy$CR_OLS[i - 1] * (1 + Trading_Strategy$ret_OLS[i] / 100)
Trading_Strategy$CR_LASSO[i] <-
Trading_Strategy$CR_LASSO[i - 1] * (1 + Trading_Strategy$ret_LASSO[i] / 100)
Trading_Strategy$CR_BuyHold[i] <-
Trading_Strategy$CR_BuyHold[i - 1] * (1 + Trading_Strategy$actual_return[i] / 100)
}
Trading_long <- Trading_Strategy %>%
dplyr::select(predicting_date, CR_OLS, CR_LASSO, CR_BuyHold) %>%
tidyr::pivot_longer(-predicting_date,
names_to = "Strategy",
values_to = "CR")
ggplot(Trading_long,
aes(x = predicting_date, y = CR, color = Strategy)) +
geom_line(linewidth = 0.8) +
theme_minimal() +
labs(
title = "Cumulative returns of simple strategies based on regression forecasts",
x = "Date",
y = "Cumulative return"
) +
theme(legend.position = "top")
# Make sure use_python(...) is set above before calling this
ez_out <- run_ez_pipeline(
retrain = FALSE,
num_episodes = 1
)
str(ez_out)
